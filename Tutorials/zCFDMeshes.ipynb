{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# zCFD mesh guide\n",
    "---\n",
    "\n",
    "This notebook provides an interactive description of the zCFD mesh format. \n",
    "\n",
    "zCFD meshes are unstructured, cell centred meshes, stored in hdf5 format.\n",
    "\n",
    "To interact with hdf5 files in python, import the h5py module- note this comes shipped within the zCFD virtual environment. A mesh can be loaded with the method `File`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "fname = '../data/MDO_125K.h5'\n",
    "h5file = h5py.File(fname,\"r\")\n",
    "\n",
    "print('Mesh file: {} loaded successfully'.format(fname))"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 57,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mesh file: ../data/MDO_125K.h5 loaded successfully\n"
     ]
    }
   ]
  },
  {
   "source": [
    "## Groups\n",
    "---\n",
    "At the highest level the mesh has a group called 'mesh'. Groups in hdf5 format serve as 'directory like' to provide structure to the dataset, and can have aspects of python dictionary convention such as `keys`, `values`, and iteration support. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['mesh']\n"
     ]
    }
   ],
   "source": [
    "groups = list(h5file.keys())\n",
    "print(groups)"
   ]
  },
  {
   "source": [
    "The mesh group contains all the mesh data, and can be extracted using the `get` method."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mesh group successfully loaded\n"
     ]
    }
   ],
   "source": [
    "mesh = h5file.get('mesh')\n",
    "\n",
    "print('Mesh group successfully loaded')"
   ]
  },
  {
   "source": [
    "## Attributes\n",
    "---\n",
    "\n",
    "The mesh group has 2 int64_t formatted attributes- `numCells`, and `numFaces`. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['numCells', 'numFaces']\n"
     ]
    }
   ],
   "source": [
    "attributes = list(mesh.attrs.keys())\n",
    "print(attributes)"
   ]
  },
  {
   "source": [
    "Or if using dictionary notation-"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['numCells', 'numFaces']\n"
     ]
    }
   ],
   "source": [
    "attributes = list(h5file['mesh'].attrs.keys())\n",
    "print(attributes)"
   ]
  },
  {
   "source": [
    "As before these attributes can be accessed using the `get` method:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "124800 382720\n"
     ]
    }
   ],
   "source": [
    "numCells = int(mesh.attrs.get('numCells'))\n",
    "numFaces = int(mesh.attrs.get('numFaces'))\n",
    "\n",
    "print(numCells, numFaces)"
   ]
  },
  {
   "source": [
    "Alternatively the extraction can be automated using the `items` method:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Attributes: {'numCells': array([[124800]], dtype=int32), 'numFaces': array([[382720]], dtype=int32)}\nAttributes: {'numCells': 124800, 'numFaces': 382720}\n"
     ]
    }
   ],
   "source": [
    "attributes = dict(mesh.attrs.items())\n",
    "\n",
    "print('Attributes: {}'.format(attributes))\n",
    "\n",
    "# Change to int format using dictionary comprehension\n",
    "attributes = {item:int(attributes[item]) for item in attributes}\n",
    "\n",
    "print('Attributes: {}'.format(attributes))"
   ]
  },
  {
   "source": [
    "## Datasets\n",
    "---\n",
    "Datasets are analogous to arrays in hdf5 format. They are where the physical data is stored in the zCFD mesh. The 6 required datasets are:\n",
    "* faceBC\n",
    "* faceCell\n",
    "* faceInfo\n",
    "* faceNodes\n",
    "* faceType\n",
    "* nodeVertex\n",
    "\n",
    "*note from here on the mesh group is used to explore the data structure, but it can be exchanged for `h5file['mesh']` for equivalent results*"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['cellFace', 'faceBC', 'faceCell', 'faceInfo', 'faceNodes', 'faceType', 'nodeVertex']\n"
     ]
    }
   ],
   "source": [
    "datasets = list(mesh.keys())\n",
    "\n",
    "print(datasets)"
   ]
  },
  {
   "source": [
    "Similarly to the attributes, a dictionary of datasets can be obtained using the `items` method and dictionary comprehension."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'cellFace': array([     0,      1,      2, ..., 382717, 382718, 382719], dtype=int32), 'faceBC': array([[9],\n       [0],\n       [0],\n       ...,\n       [9],\n       [9],\n       [9]], dtype=int32), 'faceCell': array([[     0, 124800],\n       [     0,      1],\n       [     0,  88331],\n       ...,\n       [124799, 141437],\n       [124799, 141438],\n       [124799, 141439]], dtype=int32), 'faceInfo': array([[2, 0],\n       [0, 0],\n       [0, 0],\n       ...,\n       [2, 0],\n       [2, 0],\n       [2, 0]], dtype=int32), 'faceNodes': array([[    13],\n       [   286],\n       [   273],\n       ...,\n       [133204],\n       [133192],\n       [133191]], dtype=int32), 'faceType': array([[4],\n       [4],\n       [4],\n       ...,\n       [4],\n       [4],\n       [4]], dtype=int32), 'nodeVertex': array([[ 3.31865544e+02,  4.49082846e-03,  0.00000000e+00],\n       [ 2.33772516e+02,  3.93497335e-03, -2.82267962e+00],\n       [ 1.50669013e+02,  4.49082846e-03, -5.12891315e+00],\n       ...,\n       [ 2.38361856e+02,  2.90701659e+02,  2.96788236e+02],\n       [ 2.93968040e+02,  2.90701659e+02,  2.96788236e+02],\n       [ 3.72019762e+02,  2.90701659e+02,  2.96788236e+02]])}\n"
     ]
    }
   ],
   "source": [
    "datasets = dict(mesh.items())\n",
    "datasets = {item:np.array(datasets[item]) for item in datasets}\n",
    "print(datasets)"
   ]
  },
  {
   "source": [
    "Going through these logically then:\n",
    "\n",
    "## nodeVertex\n",
    "\n",
    "`[numNodes x 3]` array\n",
    "\n",
    "where `numNodes` is the total number of unique nodes in the mesh. Each row is an `[x,y,z]` coordinate for a node location."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "numNodes = datasets['nodeVertex'].shape[0]\n",
    "\n",
    "print('numNodes = {}'.format(numNodes))\n",
    "print('nodeVertex:')\n",
    "print(datasets['nodeVertex'])"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 66,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "numNodes = 133205\nnodeVertex:\n[[ 3.31865544e+02  4.49082846e-03  0.00000000e+00]\n [ 2.33772516e+02  3.93497335e-03 -2.82267962e+00]\n [ 1.50669013e+02  4.49082846e-03 -5.12891315e+00]\n ...\n [ 2.38361856e+02  2.90701659e+02  2.96788236e+02]\n [ 2.93968040e+02  2.90701659e+02  2.96788236e+02]\n [ 3.72019762e+02  2.90701659e+02  2.96788236e+02]]\n"
     ]
    }
   ]
  },
  {
   "source": [
    "## faceType\n",
    "\n",
    "`[numFaces x 1]` array\n",
    "\n",
    "The number of nodes making up each face. `Face0` has `faceType[0]` nodes etc...\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "faceType shape = (382720, 1)\nfaceType:\n[[4]\n [4]\n [4]\n ...\n [4]\n [4]\n [4]]\n"
     ]
    }
   ],
   "source": [
    "print('faceType shape = {}'.format(datasets['faceType'].shape))\n",
    "print('faceType:')\n",
    "print(datasets['faceType'])"
   ]
  },
  {
   "source": [
    "## faceNodes\n",
    "\n",
    "`[sum(faceType) x 1]` array\n",
    "\n",
    "Ordered list of nodes making up each face. The order is determined by the commulative summation of the `faceType` dataset. For indexing indvidual faces it can be useful to define an additional data type of `faceIndex`, where each entry is the sum of `faceType` up to the particular index, then the nodes in face n are `faceNodes[faceIndex[n]:faceIndex[n]+faceType[n]]`.\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "sum(faceType) = 1530880\n",
      "faceNodes shape = (1530880, 1)\n",
      "faceNodes:\n",
      "[[    13]\n",
      " [   286]\n",
      " [   273]\n",
      " ...\n",
      " [133204]\n",
      " [133192]\n",
      " [133191]]\n",
      "faceIndex:\n",
      "[[      0]\n",
      " [      4]\n",
      " [      8]\n",
      " ...\n",
      " [1530868]\n",
      " [1530872]\n",
      " [1530876]]\n"
     ]
    }
   ],
   "source": [
    "print('sum(faceType) = {}'.format(np.sum(datasets['faceType'])))\n",
    "print('faceNodes shape = {}'.format(datasets['faceNodes'].shape))\n",
    "\n",
    "print('faceNodes:')\n",
    "print(datasets['faceNodes'])\n",
    "\n",
    "# Create faceIndex array\n",
    "faceIndex = np.zeros_like(datasets['faceType'])\n",
    "\n",
    "for i in range(attributes['numFaces']-1):\n",
    "    faceIndex[i+1] = datasets['faceType'][i+1] + faceIndex[i]\n",
    "\n",
    "print('faceIndex:')\n",
    "print(faceIndex)"
   ]
  },
  {
   "source": [
    "## Example: find the nodes making up a random face from the mesh"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "faceID: 312621\nnodes in face: 4\nnode: 1, id: 109421, [x,y,z]: [[[ 52.09053259  44.24420207 -10.13687813]]]\nnode: 2, id: 109422, [x,y,z]: [[[51.62639787 44.47465977 -9.99349056]]]\nnode: 3, id: 109409, [x,y,z]: [[[51.84805289 43.45316597 -7.0328313 ]]]\nnode: 4, id: 109408, [x,y,z]: [[[52.23318846 43.25625616 -7.13768575]]]\n"
     ]
    }
   ],
   "source": [
    "# Random face index\n",
    "faceID = np.random.randint(0,high=attributes['numFaces'])\n",
    "n_nodes = int(datasets['faceType'][faceID])\n",
    "\n",
    "print('faceID: {}'.format(faceID))\n",
    "print('nodes in face: {}'.format(n_nodes))\n",
    "\n",
    "for i in range(n_nodes):\n",
    "    print('node: {}, id: {}, [x,y,z]: {}'.format(i+1,int(datasets['faceNodes'][faceIndex[faceID]+i]),datasets['nodeVertex'][datasets['faceNodes'][faceIndex[faceID]+i]]))\n"
   ]
  },
  {
   "source": [
    "---\n",
    "## faceCell\n",
    "\n",
    "`[numFaces x 2]` array\n",
    "\n",
    "Pairs of left and right cell indices for each face in the mesh. Boundary faces should have the interior cell in the left index, with a unique, *consequtively* numbered boundary cell on the right."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "faceCell shape = (382720, 2)\nfaceCell:\n[[     0 124800]\n [     0      1]\n [     0  88331]\n ...\n [124799 141437]\n [124799 141438]\n [124799 141439]]\n"
     ]
    }
   ],
   "source": [
    "print('faceCell shape = {}'.format(datasets['faceCell'].shape))\n",
    "print('faceCell:')\n",
    "print(datasets['faceCell'])"
   ]
  },
  {
   "source": [
    "## faceBC\n",
    "\n",
    "`[numFaces x 1]` array\n",
    "\n",
    "The boundary condition to be applied to each face. Numbering here follows the fluent numbering convention:\n",
    "* 0 = NONE\n",
    "* 2 = Interior\n",
    "* 3 = Wall\n",
    "* 4 = Inflow\n",
    "* 5 = Outflow\n",
    "* 7 = Symmetry\n",
    "* 9 = Farfield\n",
    "* 12 = Periodic (Additional zone info needed)\n",
    "* 13 = Wall source (Accoustic solver only)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "faceBC shape: (382720, 1)\nfaceBC:\n[[9]\n [0]\n [0]\n ...\n [9]\n [9]\n [9]]\n"
     ]
    }
   ],
   "source": [
    "print('faceBC shape: {}'.format(datasets['faceBC'].shape))\n",
    "print('faceBC:')\n",
    "print(datasets['faceBC'])"
   ]
  },
  {
   "source": [
    "## faceInfo\n",
    "\n",
    "`[numFaces x 2]` array\n",
    "\n",
    "Zone information for each face used to initialise conditions from fluidZones. The first index should be zoneID, and the second should be 0. This is used for defining more complex boundary conditions- for example periodic faces, or multiple types of wall (slip vs non-slip) etc...\n",
    "\n",
    "If used for boundary conditions, these indexes should correspond to entries in the control dictionary."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "faceInfo shape: (382720, 2)\nfaceInfo:\n[[2 0]\n [0 0]\n [0 0]\n ...\n [2 0]\n [2 0]\n [2 0]]\n"
     ]
    }
   ],
   "source": [
    "print('faceInfo shape: {}'.format(datasets['faceInfo'].shape))\n",
    "print('faceInfo:')\n",
    "print(datasets['faceInfo'])"
   ]
  },
  {
   "source": [
    "## cellZone (optional)\n",
    "\n",
    "`[numCells x 1]` array\n",
    "\n",
    "Contains index for what mesh zone the cell is in. Becomes important for MRF (floating rotor) type simulations, where some cells will be in a rotating reference frame, and other stationary.\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Bash commands\n",
    "---\n",
    "\n",
    "There are a number of bash commands which can be useful for quick analysis of hdf5 files. These include:\n",
    "\n",
    "### `h5ls` \n",
    "\n",
    "```\n",
    "> h5ls MDO_125K.h5\n",
    "mesh                     Group\n",
    "```\n",
    "In particular h5ls -r list the group structure recursively\n",
    "```\n",
    "> h5ls -r MDO_125K.h5\n",
    "/                        Group\n",
    "/mesh                    Group\n",
    "/mesh/faceBC             Dataset {382720, 1}\n",
    "/mesh/faceCell           Dataset {382720, 2}\n",
    "/mesh/faceInfo           Dataset {382720, 2}\n",
    "/mesh/faceNodes          Dataset {1530880, 1}\n",
    "/mesh/faceType           Dataset {382720, 1}\n",
    "/mesh/nodeVertex         Dataset {133205, 3}\n",
    "```\n",
    "\n",
    "* `h5dump`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}